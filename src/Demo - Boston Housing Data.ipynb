{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Exploration: Boston House Pricing\n",
    "## Bohumír Zámečník\n",
    "http://www.neural.cz/dataset-exploration-boston-house-pricing.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will load the Boston dataset directly instead of getting\n",
    "# it through sklearn.\n",
    "df = pd.read_csv('data/Boston.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count data points and features (attributes)\n",
    "instance_count, attr_count = df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRIM = per capita crime rate by town\n",
    "# ZN = proportion of residential land zoned for lots over 25,000 sq. ft.\n",
    "# INDUS = proportion of non-retail business acres per town\n",
    "# CHAS = Charles River dummy variable\n",
    "# NOX = nitrogen oxides concentration\n",
    "# RM = avg. rooms per dwelling\n",
    "# AGE = proportion of owner-occupied units built prior to 1940\n",
    "# DIS = weighted mean of distances to five Boston employment centers\n",
    "# RAD = index of accessibility to radial highways\n",
    "# TAX = full-value property-tax rate per $10,000\n",
    "# PTRATIO = pupil-teacher ratio by town\n",
    "# LSTAT = lower status of the population (percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas offers three correlation coefficients via the corr() function:\n",
    "# Pearson, Spearman rank correlation, and Kendall Tau rank correlation\n",
    "# We'll use Pearson...\n",
    "\n",
    "pearson = df.corr(method='pearson')\n",
    "pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's look at correlation with target/answer\n",
    "corr_with_target = pearson.iloc[-1][:-1]\n",
    "corr_with_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictivity = corr_with_target.sort_values(inplace=False, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strong negative correlations are important too...\n",
    "corr_with_target[abs(corr_with_target).argsort()[::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It might be interesting to select some strong correlations between\n",
    "# attribute pairs. With a bit of Python magic it is possible:\n",
    "attrs = pearson.iloc[:-1, :-1] # all except target\n",
    "# only important correlations and not auto-correlations\n",
    "threshold = 0.5\n",
    "# {('LSTAT', 'TAX'): 0.543993, ('INDUS', 'RAD'): 0.595129, ...\n",
    "important_corrs = (attrs[abs(attrs) > threshold][attrs != 1.0]) \\\n",
    "    .unstack().dropna().to_dict()\n",
    "#     attribute pair  correlation\n",
    "# 0     (AGE, INDUS)     0.644779\n",
    "# 1     (INDUS, RAD)     0.595129\n",
    "# ...\n",
    "\n",
    "unique_important_corrs = pd.DataFrame(\n",
    "    list(set([(tuple(sorted(key)), important_corrs[key]) \\\n",
    "    for key in important_corrs])), columns=['attribute pair', 'correlation'])\n",
    "# sorted by absolute value\n",
    "unique_important_corrs = unique_important_corrs.iloc[\n",
    "    abs(unique_important_corrs['correlation']).argsort()[::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_important_corrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns  #heatmap replaces corrplot\n",
    "sns.set(rc={'figure.figsize':(11, 8)})\n",
    "# Using all correlations\n",
    "sns.heatmap(pearson, annot=True); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# display annotations and change the colors...\n",
    "sns.heatmap(pearson, cmap='coolwarm', annot=True); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a mask for the upper triangle / values above the identity diagonal\n",
    "# Remove use of the mask below to see the \"whole\" heatmap\n",
    "mask = np.zeros_like(pearson, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Add square parameter to make cells square, use the mask, remove annot\n",
    "sns.heatmap(pearson, cmap='coolwarm', mask=mask, square=True); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = df['MEDV']\n",
    "plt.hist(attr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(attr, bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(attr);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For integer-valued data (e.g., categories) automatic quantization into a pre-defined number of bins might not be the best option.\n",
    "### We'd like to quantize according the original distinct values. For that we can just compute this kind of histogram ourselves and use the bar plot.\n",
    "* Example for __RAD__ int (category) - index of accessibility to radial highways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_attr = df['RAD']\n",
    "h = cat_attr.value_counts()\n",
    "values, counts = h.index, h\n",
    "plt.bar(values, counts);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['DIS'], df['MEDV']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x, y = df['DIS'], df['MEDV']\n",
    "plt.scatter(x, y, alpha=0.5)\n",
    "\n",
    "# or via jointplot (with histograms aside):\n",
    "sns.jointplot(x, y, kind='scatter', joint_kws={'alpha':0.5});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(df['DIS'], df['MEDV'], kind='hex');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.kdeplot(df['DIS'], df['MEDV'], shade=True)\n",
    "# or \n",
    "sns.jointplot(df['DIS'], df['MEDV'], kind='kde');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "y_hat = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0a2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
